{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "from sklearn.decomposition import IncrementalPCA, PCA, TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           the vagabond and the child\n",
       "1                                            gold rush\n",
       "2                                            metropoli\n",
       "3                                          the general\n",
       "4                                           citi light\n",
       "                             ...                      \n",
       "10092                                       scaramouch\n",
       "10093                                     you cant win\n",
       "10094                                   runway to luck\n",
       "10095         the adventur of ichabod and taddÃ¤us toad\n",
       "10096    a yanke from connecticut to king arthur court\n",
       "Name: title, Length: 10097, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortX = pd.read_csv(\"./imdbmovies/features.csv\")\n",
    "genre = pd.read_csv(\"./imdbmovies/labels.csv\")\n",
    "fullX = pd.read_csv(\"./imdbmovies/features_vectorized.csv\")\n",
    "words50X = pd.read_csv(\"./imdbmovies/vectorization50.csv\", header=None)\n",
    "labelsY = pd.read_csv(\"./imdbmovies/labels.csv\")\n",
    "shortX.pop('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression without PCA\n",
    "\n",
    "C=np.power(np.e, np.random.uniform(0, 1, 10))\n",
    "start_time = time.time()\n",
    "dict_loss = {}\n",
    "dict_accuracy = {}\n",
    "for c in C:\n",
    "    dict_loss[c] = []\n",
    "    dict_accuracy[c] = []\n",
    "    for i in range (5):\n",
    "        x_train, x_test, y_train, y_test  = train_test_split(shortX, labelsY, test_size=.3)\n",
    "        lr = OneVsRestClassifier(LogisticRegression(class_weight='balanced', C=c, solver='sag', max_iter = 2500), n_jobs=-1)\n",
    "        lr.fit(x_train, y_train)\n",
    "        y_pred = lr.predict(x_test)\n",
    "        score=lr.score(x_test, y_test)\n",
    "        hl = hamming_loss(y_test, y_pred)\n",
    "        dict_loss[c].append(hl)\n",
    "        dict_accuracy[c].append(score)\n",
    "        \n",
    "print(\"Time to load data: {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "# Plotting the accuracy and hamming loss vs C values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "ax2 = ax.twinx()\n",
    "for c, x in dict_loss.items(): \n",
    "    avg_loss = {k:np.mean(np.array(v)) for k,v in dict_loss.items()}\n",
    "    avg_score = {k:np.mean(np.array(v)) for k,v in dict_accuracy.items()}\n",
    "    list1 = sorted(avg_loss.items())\n",
    "    list2 = sorted(avg_score.items())\n",
    "    x_plot, y_plot = zip(*list1)\n",
    "    ax.plot(x_plot, y_plot, color='orange',marker='d',markersize=10)\n",
    "    x, y = zip(*list2)\n",
    "    ax2.plot(x,y, color='green',marker='d',markersize=10)\n",
    "\n",
    "ax.set_ylabel('Accuracy',fontsize=10)\n",
    "ax2.set_ylabel('Hamming Loss',fontsize=10)\n",
    "ax.legend(['Accuracy'],loc=2,fontsize=15)\n",
    "ax2.legend(['Loss'],loc=1,fontsize=15)\n",
    "ax.set_xlabel('C- values',fontsize=10)\n",
    "plt.title(\"Accuracy and Hamming Loss vs C- values without PCA\")\n",
    "ax.set_xscale('log')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Logistic Regression with PCA\n",
    "\n",
    "start_time = time.time()\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "dict_loss_pca = {}\n",
    "dict_accuracy_pca = {}\n",
    "for c in C:\n",
    "    dict_loss_pca[c] = []\n",
    "    dict_accuracy_pca[c] = []\n",
    "    for i in range (5):\n",
    "        x_train, x_test, y_train, y_test  = train_test_split(shortX, labelsY, test_size=.3)\n",
    "        pca.fit(x_train)\n",
    "        x_train_reduced = pca.transform((x_train))\n",
    "        x_test_reduced = pca.transform((x_test))\n",
    "        lr_pca = OneVsRestClassifier(LogisticRegression(class_weight='balanced', C=c, solver='sag', max_iter = 5000), n_jobs=-1)\n",
    "        lr_pca.fit(x_train_reduced, y_train)\n",
    "        y_pred = lr_pca.predict(x_test_reduced)\n",
    "        score=lr_pca.score(x_test_reduced, y_test)\n",
    "        hl = hamming_loss(y_test, y_pred)\n",
    "        dict_loss_pca[c].append(hl)\n",
    "        dict_accuracy_pca[c].append(score)\n",
    "\n",
    "\n",
    "print(\"Time to load data: {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "# Plotting LR with PCA\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "ax2 = ax.twinx()\n",
    "for c, x in dict_loss.items(): \n",
    "    avg_loss = {k:np.mean(np.array(v)) for k,v in dict_loss_pca.items()}\n",
    "    avg_score = {k:np.mean(np.array(v)) for k,v in dict_accuracy_pca.items()}\n",
    "    list1 = sorted(avg_loss.items())\n",
    "    list2 = sorted(avg_score.items())\n",
    "    x_plot, y_plot = zip(*list1)\n",
    "    ax.plot(x_plot, y_plot, color='orange',marker='d',markersize=10)\n",
    "    x, y = zip(*list2)\n",
    "    ax2.plot(x,y, color='green',marker='d',markersize=10)\n",
    "\n",
    "ax.set_ylabel('Accuracy',fontsize=10)\n",
    "ax2.set_ylabel('Hamming Loss',fontsize=10)\n",
    "ax.legend(['Accuracy'],loc=2,fontsize=15)\n",
    "ax2.legend(['Loss'],loc=1,fontsize=15)\n",
    "ax.set_xlabel('C- values',fontsize=10)\n",
    "plt.title(\"Accuracy and Hamming Loss vs C- values with PCA\")\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(arr):\n",
    "    if arr[arr  > 0].size == 0:\n",
    "        result = np.zeros(arr.shape)\n",
    "        maxIdx = np.argmax(arr)\n",
    "        result[maxIdx] = 1\n",
    "        return result\n",
    "    else:\n",
    "        result = arr\n",
    "        result[result > 0] = 1\n",
    "        result[result <= 0] = 0\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titleKey = {0: \"No Title Data\", 1: \"50% Covar Title Data\", 2: \"Full Title Data\"}\n",
    "Loss = {v: [] for k, v in titleKey.items()}\n",
    "Score = {v: [] for k, v in titleKey.items()}\n",
    "for t in range(15):\n",
    "    for i, X in enumerate((shortX, shortX.join(words50X), fullX)):\n",
    "        title = titleKey[i]\n",
    "        X_train, X_test, y_train, y_test  = train_test_split(X, labelsY, test_size=.1)\n",
    "        SVM = LinearSVC(dual=False, max_iter=10000)\n",
    "        clf = OneVsRestClassifier(SVM)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.decision_function(X_test)\n",
    "        y_pred = np.apply_along_axis(get_pred, 1, y_pred)\n",
    "        ham_loss = hamming_loss(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        Score[title].append(acc)\n",
    "        Loss[title].append(ham_loss)\n",
    "        \n",
    "plt.clf()\n",
    "_, ax = plt.subplots(figsize=(24,12))\n",
    "for k, v in trialScore.items():\n",
    "    ax.plot(v, label=k)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.title(\"Accuracy Of Datasets\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "_, ax = plt.subplots()\n",
    "for k, v in trialLoss.items(figsize=(24,12)):\n",
    "    ax.plot(v, label=k)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.title(\"Hamming Loss Of Datasets\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([    0,     1,     2,     3,     4,     5,     8,     9,    10,\\n               11,\\n            ...\\n            10085, 10086, 10087, 10089, 10090, 10092, 10093, 10094, 10095,\\n            10096],\\n           dtype='int64', length=9087)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-66dfd16dbc0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mgenre_neigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 raise KeyError(\n\u001b[1;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1177\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     )\n\u001b[1;32m   1179\u001b[0m                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([    0,     1,     2,     3,     4,     5,     8,     9,    10,\\n               11,\\n            ...\\n            10085, 10086, 10087, 10089, 10090, 10092, 10093, 10094, 10095,\\n            10096],\\n           dtype='int64', length=9087)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "features = fullX.ton\n",
    "# k-fold crossvalidation with 10 folds\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# calculate accuracy and loss\n",
    "result = np.zeros(10)\n",
    "loss = np.zeros(10)\n",
    "genre_neigh = KNeighborsClassifier(n_neighbors=13)\n",
    "i = 0\n",
    "for train_idx, test_idx in kf.split(features):\n",
    "    X_train2, X_test2 = features[train_idx], features[test_idx]\n",
    "    y_train2, y_test2 = labels[train_idx], labels[test_idx]\n",
    "    genre_neigh.fit(X_train2, y_train2)\n",
    "    y_predict2 = genre_neigh.predict(X_test2)\n",
    "    result[i] = genre_neigh.score(X_test2, y_test2)\n",
    "    loss[i] = hamming_loss(y_test2, y_predict2)\n",
    "    i += 1\n",
    "    \n",
    "# calculate accuracy and loss with 50% covar, 10 fold CV\n",
    "result_50 = np.zeros(10)\n",
    "loss_50 = np.zeros(10)\n",
    "i = 0\n",
    "for train_idx, test_idx in kf.split(words50):\n",
    "    X_train3, X_test3 = words50[train_idx], words50[test_idx]\n",
    "    y_train3, y_test3 = labels[train_idx], labels[test_idx]\n",
    "    genre_neigh.fit(X_train3, y_train3)\n",
    "    y_predict3 = genre_neigh.predict(X_test3)\n",
    "    result_50[i] = genre_neigh.score(X_test3, y_test3)\n",
    "    loss_50[i] = hamming_loss(y_test3, y_predict3)\n",
    "    i += 1\n",
    "    \n",
    "# plot subset accuracy and Hamming loss\n",
    "fig, ax1 = plt.subplots(figsize=(24,12))\n",
    "ax1.set_xlabel('Folds',fontsize=20)\n",
    "ax1.set_ylabel('Subset Accuracy',fontsize=20)\n",
    "ax1.plot(np.arange(1,11), result, color='red',marker='o',markersize=10)\n",
    "ax1.legend(['Accuracy'],loc=2,fontsize=20)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.set_ylabel('Hamming Loss',fontsize=20)\n",
    "ax2.plot(np.arange(1,11), loss, color='blue',marker='s',markersize=10)\n",
    "ax2.legend(['Loss'],loc=1,fontsize=20)\n",
    "\n",
    "plt.title('10-fold crossvalidation, KNN',fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.grid(1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleKey = {0: \"No Title Data\", 2: \"Full Title Data\"}\n",
    "trialLoss = {v: [] for k, v in titleKey.items()}\n",
    "trialScore = {v: [] for k, v in titleKey.items()}\n",
    "for t in range(10):\n",
    "    print(\"Starting trial \", t)\n",
    "    for i, X in enumerate((shortX, fullX)):\n",
    "        title = titleKey[i]\n",
    "        X_train, X_test, y_train, y_test  = train_test_split(X, labelsY, test_size=.1)\n",
    "        RFC = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "        clf = OneVsRestClassifier(RFC)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        ham_loss = hamming_loss(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        trialScore[title].append(acc)\n",
    "        trialLoss[title].append(ham_loss)\n",
    "        \n",
    "plt.clf()\n",
    "_, ax = plt.subplots(figsize=(24,12))\n",
    "for k, v in trialScore.items():\n",
    "    ax.plot(v, label=k)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.title(\"Accuracy Of Datasets\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "_, ax = plt.subplots(figsize=(24,12))\n",
    "for k, v in trialLoss.items():\n",
    "    ax.plot(v, label=k)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.title(\"Hamming Loss Of Datasets\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
