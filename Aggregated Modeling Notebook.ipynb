{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "from sklearn.decomposition import IncrementalPCA, PCA, TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortX = pd.read_csv(\"./imdbmovies/features.csv\")\n",
    "fullX = pd.read_csv(\"./imdbmovies/features_vectorized.csv\")\n",
    "words50X = pd.read_csv(\"./imdbmovies/vectorization50.csv\", header=None)\n",
    "labelsY = pd.read_csv(\"./imdbmovies/labels.csv\")\n",
    "del shortX.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression without PCA\n",
    "\n",
    "C=np.power(np.e, np.random.uniform(0, 1, 10))\n",
    "start_time = time.time()\n",
    "dict_loss = {}\n",
    "dict_accuracy = {}\n",
    "for c in C:\n",
    "    dict_loss[c] = []\n",
    "    dict_accuracy[c] = []\n",
    "    for i in range (5):\n",
    "        x_train, x_test, y_train, y_test  = train_test_split(shortX, labelsY, test_size=.3)\n",
    "        lr = OneVsRestClassifier(LogisticRegression(class_weight='balanced', C=c, solver='sag', max_iter = 2500), n_jobs=-1)\n",
    "        lr.fit(x_train, y_train)\n",
    "        y_pred = lr.predict(x_test)\n",
    "        score=lr.score(x_test, y_test)\n",
    "        hl = hamming_loss(y_test, y_pred)\n",
    "        dict_loss[c].append(hl)\n",
    "        dict_accuracy[c].append(score)\n",
    "        \n",
    "print(\"Time to load data: {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "# Plotting the accuracy and hamming loss vs C values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "ax2 = ax.twinx()\n",
    "for c, x in dict_loss.items(): \n",
    "    avg_loss = {k:np.mean(np.array(v)) for k,v in dict_loss.items()}\n",
    "    avg_score = {k:np.mean(np.array(v)) for k,v in dict_accuracy.items()}\n",
    "    list1 = sorted(avg_loss.items())\n",
    "    list2 = sorted(avg_score.items())\n",
    "    x_plot, y_plot = zip(*list1)\n",
    "    ax.plot(x_plot, y_plot, color='orange',marker='d',markersize=10)\n",
    "    x, y = zip(*list2)\n",
    "    ax2.plot(x,y, color='green',marker='d',markersize=10)\n",
    "\n",
    "ax.set_ylabel('Accuracy',fontsize=10)\n",
    "ax2.set_ylabel('Hamming Loss',fontsize=10)\n",
    "ax.legend(['Accuracy'],loc=2,fontsize=15)\n",
    "ax2.legend(['Loss'],loc=1,fontsize=15)\n",
    "ax.set_xlabel('C- values',fontsize=10)\n",
    "plt.title(\"Accuracy and Hamming Loss vs C- values without PCA\")\n",
    "ax.set_xscale('log')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Logistic Regression with PCA\n",
    "\n",
    "start_time = time.time()\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "dict_loss_pca = {}\n",
    "dict_accuracy_pca = {}\n",
    "for c in C:\n",
    "    dict_loss_pca[c] = []\n",
    "    dict_accuracy_pca[c] = []\n",
    "    for i in range (5):\n",
    "        x_train, x_test, y_train, y_test  = train_test_split(shortX, labelsY, test_size=.3)\n",
    "        pca.fit(x_train)\n",
    "        x_train_reduced = pca.transform((x_train))\n",
    "        x_test_reduced = pca.transform((x_test))\n",
    "        lr_pca = OneVsRestClassifier(LogisticRegression(class_weight='balanced', C=c, solver='sag', max_iter = 5000), n_jobs=-1)\n",
    "        lr_pca.fit(x_train_reduced, y_train)\n",
    "        y_pred = lr_pca.predict(x_test_reduced)\n",
    "        score=lr_pca.score(x_test_reduced, y_test)\n",
    "        hl = hamming_loss(y_test, y_pred)\n",
    "        dict_loss_pca[c].append(hl)\n",
    "        dict_accuracy_pca[c].append(score)\n",
    "\n",
    "\n",
    "print(\"Time to load data: {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "# Plotting LR with PCA\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "ax2 = ax.twinx()\n",
    "for c, x in dict_loss.items(): \n",
    "    avg_loss = {k:np.mean(np.array(v)) for k,v in dict_loss_pca.items()}\n",
    "    avg_score = {k:np.mean(np.array(v)) for k,v in dict_accuracy_pca.items()}\n",
    "    list1 = sorted(avg_loss.items())\n",
    "    list2 = sorted(avg_score.items())\n",
    "    x_plot, y_plot = zip(*list1)\n",
    "    ax.plot(x_plot, y_plot, color='orange',marker='d',markersize=10)\n",
    "    x, y = zip(*list2)\n",
    "    ax2.plot(x,y, color='green',marker='d',markersize=10)\n",
    "\n",
    "ax.set_ylabel('Accuracy',fontsize=10)\n",
    "ax2.set_ylabel('Hamming Loss',fontsize=10)\n",
    "ax.legend(['Accuracy'],loc=2,fontsize=15)\n",
    "ax2.legend(['Loss'],loc=1,fontsize=15)\n",
    "ax.set_xlabel('C- values',fontsize=10)\n",
    "plt.title(\"Accuracy and Hamming Loss vs C- values with PCA\")\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(arr):\n",
    "    if arr[arr  > 0].size == 0:\n",
    "        result = np.zeros(arr.shape)\n",
    "        maxIdx = np.argmax(arr)\n",
    "        result[maxIdx] = 1\n",
    "        return result\n",
    "    else:\n",
    "        result = arr\n",
    "        result[result > 0] = 1\n",
    "        result[result <= 0] = 0\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titleKey = {0: \"No Title Data\", 1: \"50% Covar Title Data\", 2: \"Full Title Data\"}\n",
    "Loss = {v: [] for k, v in titleKey.items()}\n",
    "Score = {v: [] for k, v in titleKey.items()}\n",
    "for t in range(15):\n",
    "    for i, X in enumerate((shortX, shortX.join(words50X), fullX)):\n",
    "        title = titleKey[i]\n",
    "        X_train, X_test, y_train, y_test  = train_test_split(X, labelsY, test_size=.1)\n",
    "        SVM = LinearSVC(dual=False, max_iter=10000)\n",
    "        clf = OneVsRestClassifier(SVM)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.decision_function(X_test)\n",
    "        y_pred = np.apply_along_axis(get_pred, 1, y_pred)\n",
    "        ham_loss = hamming_loss(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        Score[title].append(acc)\n",
    "        Loss[title].append(ham_loss)\n",
    "        \n",
    "plt.clf()\n",
    "_, ax = plt.subplots(figsize=(24,12))\n",
    "for k, v in trialScore.items():\n",
    "    ax.plot(v, label=k)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.title(\"Accuracy Of Datasets\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "_, ax = plt.subplots()\n",
    "for k, v in trialLoss.items(figsize=(24,12)):\n",
    "    ax.plot(v, label=k)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.title(\"Hamming Loss Of Datasets\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fullX.to_numpy()\n",
    "labels = labelsY.to_numpy()\n",
    "# k-fold crossvalidation with 10 folds\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# calculate accuracy and loss\n",
    "result = np.zeros(10)\n",
    "loss = np.zeros(10)\n",
    "genre_neigh = KNeighborsClassifier(n_neighbors=13)\n",
    "i = 0\n",
    "for train_idx, test_idx in kf.split(features):\n",
    "    X_train2, X_test2 = features[train_idx], features[test_idx]\n",
    "    y_train2, y_test2 = labels[train_idx], labels[test_idx]\n",
    "    genre_neigh.fit(X_train2, y_train2)\n",
    "    y_predict2 = genre_neigh.predict(X_test2)\n",
    "    result[i] = genre_neigh.score(X_test2, y_test2)\n",
    "    loss[i] = hamming_loss(y_test2, y_predict2)\n",
    "    i += 1\n",
    "\n",
    "words50 = words50X.to_numpy()    \n",
    "# calculate accuracy and loss with 50% covar, 10 fold CV\n",
    "result_50 = np.zeros(10)\n",
    "loss_50 = np.zeros(10)\n",
    "i = 0\n",
    "for train_idx, test_idx in kf.split(words50):\n",
    "    X_train3, X_test3 = words50[train_idx], words50[test_idx]\n",
    "    y_train3, y_test3 = labels[train_idx], labels[test_idx]\n",
    "    genre_neigh.fit(X_train3, y_train3)\n",
    "    y_predict3 = genre_neigh.predict(X_test3)\n",
    "    result_50[i] = genre_neigh.score(X_test3, y_test3)\n",
    "    loss_50[i] = hamming_loss(y_test3, y_predict3)\n",
    "    i += 1\n",
    "    \n",
    "# plot subset accuracy and Hamming loss\n",
    "fig, ax1 = plt.subplots(figsize=(24,12))\n",
    "ax1.set_xlabel('Folds',fontsize=20)\n",
    "ax1.set_ylabel('Subset Accuracy',fontsize=20)\n",
    "ax1.plot(np.arange(1,11), result, color='red',marker='o',markersize=10)\n",
    "ax1.legend(['Accuracy'],loc=2,fontsize=20)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.set_ylabel('Hamming Loss',fontsize=20)\n",
    "ax2.plot(np.arange(1,11), loss, color='blue',marker='s',markersize=10)\n",
    "ax2.legend(['Loss'],loc=1,fontsize=20)\n",
    "\n",
    "plt.title('10-fold crossvalidation, KNN',fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.grid(1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleKey = {0: \"No Title Data\", 2: \"Full Title Data\"}\n",
    "trialLoss = {v: [] for k, v in titleKey.items()}\n",
    "trialScore = {v: [] for k, v in titleKey.items()}\n",
    "for t in range(10):\n",
    "    print(\"Starting trial \", t)\n",
    "    for i, X in enumerate((shortX, fullX)):\n",
    "        title = titleKey[i]\n",
    "        X_train, X_test, y_train, y_test  = train_test_split(X, labelsY, test_size=.1)\n",
    "        RFC = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "        clf = OneVsRestClassifier(RFC)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        ham_loss = hamming_loss(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        trialScore[title].append(acc)\n",
    "        trialLoss[title].append(ham_loss)\n",
    "        \n",
    "plt.clf()\n",
    "_, ax = plt.subplots(figsize=(24,12))\n",
    "for k, v in trialScore.items():\n",
    "    ax.plot(v, label=k)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.title(\"Accuracy Of Datasets\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "_, ax = plt.subplots(figsize=(24,12))\n",
    "for k, v in trialLoss.items():\n",
    "    ax.plot(v, label=k)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Trials\")\n",
    "plt.title(\"Hamming Loss Of Datasets\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
